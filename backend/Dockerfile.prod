# Production Dockerfile for Order Management System
# Installs all services (Airflow + FastAPI) in a single container
# Uses start.sh to manage background processes and run FastAPI as main service

FROM python:3.12-slim

# Set working directory
WORKDIR /opt/airflow

# Set environment variables
ENV AIRFLOW_HOME=/opt/airflow \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/opt/airflow/backend \
    PIP_NO_CACHE_DIR=1 \
    AIRFLOW__CORE__LOAD_EXAMPLES=False \
    AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags \
    AIRFLOW__CORE__PLUGINS_FOLDER=/opt/airflow/plugins \
    AIRFLOW__CORE__EXECUTOR=LocalExecutor \
    AIRFLOW__CORE__FERNET_KEY=rGTaoR2tUFcZMDRtEDO-DGgp6e4vuILUwpoDFQIEQxQ= \
    AIRFLOW__WEBSERVER__SECRET_KEY=a6b4104ecd5559064f5d8bb295f1b2cd \
    AIRFLOW__LOGGING__LOGGING_LEVEL=INFO \
    AIRFLOW__API__AUTH_BACKEND=airflow.api.auth.backend.basic_auth

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    libpq-dev \
    curl \
    git \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Create necessary directories
RUN mkdir -p /opt/airflow/dags \
    /opt/airflow/plugins \
    /opt/airflow/logs \
    /opt/airflow/pids \
    /opt/airflow/backend

# Copy requirements file
COPY requirements.txt /opt/airflow/requirements.txt

# Install Python dependencies
RUN pip install --no-cache-dir -r /opt/airflow/requirements.txt

# Copy application code
COPY . /opt/airflow/backend

# Copy startup script and make it executable
COPY start.sh /opt/airflow/start.sh
RUN chmod +x /opt/airflow/start.sh

# Expose ports
# 8000 - FastAPI application
# 8080 - Airflow webserver
# 5000 - Airflow scheduler (optional, for metrics)
EXPOSE 8000 8080 5000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Set the entry point to the start script
ENTRYPOINT ["/opt/airflow/start.sh"]
